{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Method Description***\n",
    "\n",
    "Use your system for Assignment 1 to produce initial results (1000 documents for each query), then re-rank them based on a new similarity scores between the query and each selected document. You can produce vectors for the query and each of the selected documents using various versions of sent2vec, doc2vec, BERT, or the universal sentence encoder. You can also use pre-trained word embeddings and assemble them to produce query/document embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kaishuowang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.9/site-packages (2.1.0)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.9/site-packages (from sentence-transformers) (0.1.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/site-packages (from sentence-transformers) (1.0.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.9/site-packages (from sentence-transformers) (4.12.5)\n",
      "Requirement already satisfied: tokenizers>=0.10.3 in /usr/local/lib/python3.9/site-packages (from sentence-transformers) (0.10.3)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.9/site-packages (from sentence-transformers) (3.6.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/site-packages (from sentence-transformers) (4.62.3)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.9/site-packages (from sentence-transformers) (1.10.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/site-packages (from sentence-transformers) (0.11.1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/site-packages (from sentence-transformers) (0.1.96)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.9/site-packages (from sentence-transformers) (1.7.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/site-packages (from sentence-transformers) (1.21.3)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers) (3.10.0.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/kaishuowang/Library/Python/3.9/lib/python/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.11.10)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.46)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.9/site-packages (from nltk->sentence-transformers) (8.0.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.9/site-packages (from nltk->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/site-packages (from scikit-learn->sentence-transformers) (3.0.0)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.9/site-packages (from torchvision->sentence-transformers) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.9/site-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.10.8)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.9/site-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import string\n",
    "!pip install -U sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Data Importing***\n",
    "\n",
    "In this step, we will import documents, queries, and results from assignment 1. And we will merge all three tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queryID</th>\n",
       "      <th>unused</th>\n",
       "      <th>docID</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MB001</td>\n",
       "      <td>Q0</td>\n",
       "      <td>30198105513140224</td>\n",
       "      <td>1</td>\n",
       "      <td>0.865</td>\n",
       "      <td>myRun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MB001</td>\n",
       "      <td>Q0</td>\n",
       "      <td>29552940691759104</td>\n",
       "      <td>2</td>\n",
       "      <td>0.786</td>\n",
       "      <td>myRun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MB001</td>\n",
       "      <td>Q0</td>\n",
       "      <td>29983478363717633</td>\n",
       "      <td>3</td>\n",
       "      <td>0.758</td>\n",
       "      <td>myRun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MB001</td>\n",
       "      <td>Q0</td>\n",
       "      <td>30260724248870912</td>\n",
       "      <td>4</td>\n",
       "      <td>0.722</td>\n",
       "      <td>myRun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MB001</td>\n",
       "      <td>Q0</td>\n",
       "      <td>33823403328671744</td>\n",
       "      <td>5</td>\n",
       "      <td>0.695</td>\n",
       "      <td>myRun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MB001</td>\n",
       "      <td>Q0</td>\n",
       "      <td>34703780100448257</td>\n",
       "      <td>6</td>\n",
       "      <td>0.688</td>\n",
       "      <td>myRun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MB001</td>\n",
       "      <td>Q0</td>\n",
       "      <td>29059262076420096</td>\n",
       "      <td>7</td>\n",
       "      <td>0.680</td>\n",
       "      <td>myRun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MB001</td>\n",
       "      <td>Q0</td>\n",
       "      <td>29486393336008704</td>\n",
       "      <td>8</td>\n",
       "      <td>0.668</td>\n",
       "      <td>myRun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MB001</td>\n",
       "      <td>Q0</td>\n",
       "      <td>30319208176820224</td>\n",
       "      <td>9</td>\n",
       "      <td>0.664</td>\n",
       "      <td>myRun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MB001</td>\n",
       "      <td>Q0</td>\n",
       "      <td>29564786882646016</td>\n",
       "      <td>10</td>\n",
       "      <td>0.661</td>\n",
       "      <td>myRun</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  queryID unused              docID  rank  score    tag\n",
       "0   MB001     Q0  30198105513140224     1  0.865  myRun\n",
       "1   MB001     Q0  29552940691759104     2  0.786  myRun\n",
       "2   MB001     Q0  29983478363717633     3  0.758  myRun\n",
       "3   MB001     Q0  30260724248870912     4  0.722  myRun\n",
       "4   MB001     Q0  33823403328671744     5  0.695  myRun\n",
       "5   MB001     Q0  34703780100448257     6  0.688  myRun\n",
       "6   MB001     Q0  29059262076420096     7  0.680  myRun\n",
       "7   MB001     Q0  29486393336008704     8  0.668  myRun\n",
       "8   MB001     Q0  30319208176820224     9  0.664  myRun\n",
       "9   MB001     Q0  29564786882646016    10  0.661  myRun"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read results of assignment 1\n",
    "results_A1 = pd.read_csv('Results_fromA1.txt', sep=' ', header=None)\n",
    "results_A1.columns = ['queryID', 'unused', 'docID', 'rank', 'score', 'tag']\n",
    "\n",
    "results_A1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docID</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34952194402811904</td>\n",
       "      <td>Save BBC World Service from Savage Cuts http:/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34952186328784896</td>\n",
       "      <td>a lot of people always make fun about the end ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34952041415581696</td>\n",
       "      <td>ReThink Group positive in outlook: Technology ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34952018120409088</td>\n",
       "      <td>'Zombie' fund manager Phoenix appoints new CEO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34952008683229185</td>\n",
       "      <td>Latest:: Top World Releases http://globalclass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34951899295920129</td>\n",
       "      <td>CDT presents ALICE IN WONDERLAND - Catonsville...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>34951860221648896</td>\n",
       "      <td>Territory Manager: Location: Calgary, Alberta,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34951846736953344</td>\n",
       "      <td>BBC News - Today - Free school funding plans '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>34951766319706112</td>\n",
       "      <td>Manchester City Council details saving cuts pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>34951749731090432</td>\n",
       "      <td>http://bit.ly/e0ujdP, if you are interested in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               docID                                           document\n",
       "0  34952194402811904  Save BBC World Service from Savage Cuts http:/...\n",
       "1  34952186328784896  a lot of people always make fun about the end ...\n",
       "2  34952041415581696  ReThink Group positive in outlook: Technology ...\n",
       "3  34952018120409088  'Zombie' fund manager Phoenix appoints new CEO...\n",
       "4  34952008683229185  Latest:: Top World Releases http://globalclass...\n",
       "5  34951899295920129  CDT presents ALICE IN WONDERLAND - Catonsville...\n",
       "6  34951860221648896  Territory Manager: Location: Calgary, Alberta,...\n",
       "7  34951846736953344  BBC News - Today - Free school funding plans '...\n",
       "8  34951766319706112  Manchester City Council details saving cuts pl...\n",
       "9  34951749731090432  http://bit.ly/e0ujdP, if you are interested in..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read documents\n",
    "documents = pd.read_csv('Trec_microblog11.txt', sep='\\t', header=None)\n",
    "\n",
    "# This step will seperate the document into two columns - docID and document itself.\n",
    "documents.columns = ['docID', 'document']\n",
    "\n",
    "# convert column docID to string\n",
    "documents['docID'] = documents['docID'].apply(lambda x: str(x))\n",
    "\n",
    "# Show top 10 documents\n",
    "documents.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queryID</th>\n",
       "      <th>unused</th>\n",
       "      <th>docID</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>tag</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MB001</td>\n",
       "      <td>Q0</td>\n",
       "      <td>30198105513140224</td>\n",
       "      <td>1</td>\n",
       "      <td>0.865</td>\n",
       "      <td>myRun</td>\n",
       "      <td>BBC News - BBC World Service cuts to be outlin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MB001</td>\n",
       "      <td>Q0</td>\n",
       "      <td>29552940691759104</td>\n",
       "      <td>2</td>\n",
       "      <td>0.786</td>\n",
       "      <td>myRun</td>\n",
       "      <td>BBC to cut 360 jobs as it cuts online budget: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MB001</td>\n",
       "      <td>Q0</td>\n",
       "      <td>29983478363717633</td>\n",
       "      <td>3</td>\n",
       "      <td>0.758</td>\n",
       "      <td>myRun</td>\n",
       "      <td>[BBC News] Major cuts to BBC World Service: BB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MB001</td>\n",
       "      <td>Q0</td>\n",
       "      <td>30260724248870912</td>\n",
       "      <td>4</td>\n",
       "      <td>0.722</td>\n",
       "      <td>myRun</td>\n",
       "      <td>BBC World Service outlines cuts to staff http:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MB001</td>\n",
       "      <td>Q0</td>\n",
       "      <td>33823403328671744</td>\n",
       "      <td>5</td>\n",
       "      <td>0.695</td>\n",
       "      <td>myRun</td>\n",
       "      <td>World Service Cuts: Why We Need the BBC http:/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MB001</td>\n",
       "      <td>Q0</td>\n",
       "      <td>34703780100448257</td>\n",
       "      <td>6</td>\n",
       "      <td>0.688</td>\n",
       "      <td>myRun</td>\n",
       "      <td>Another great staff meeting at AHS. We have st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MB001</td>\n",
       "      <td>Q0</td>\n",
       "      <td>29059262076420096</td>\n",
       "      <td>7</td>\n",
       "      <td>0.680</td>\n",
       "      <td>myRun</td>\n",
       "      <td>Is your staff safe? Who is training your staff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MB001</td>\n",
       "      <td>Q0</td>\n",
       "      <td>29486393336008704</td>\n",
       "      <td>8</td>\n",
       "      <td>0.668</td>\n",
       "      <td>myRun</td>\n",
       "      <td>BBC to shed nearly a quarter of online staff -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MB001</td>\n",
       "      <td>Q0</td>\n",
       "      <td>30319208176820224</td>\n",
       "      <td>9</td>\n",
       "      <td>0.664</td>\n",
       "      <td>myRun</td>\n",
       "      <td>I think the BBC world service could be saved.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MB001</td>\n",
       "      <td>Q0</td>\n",
       "      <td>29564786882646016</td>\n",
       "      <td>10</td>\n",
       "      <td>0.661</td>\n",
       "      <td>myRun</td>\n",
       "      <td>BBC News - BBC to cut online budget by 25% htt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  queryID unused              docID  rank  score    tag  \\\n",
       "0   MB001     Q0  30198105513140224     1  0.865  myRun   \n",
       "1   MB001     Q0  29552940691759104     2  0.786  myRun   \n",
       "2   MB001     Q0  29983478363717633     3  0.758  myRun   \n",
       "3   MB001     Q0  30260724248870912     4  0.722  myRun   \n",
       "4   MB001     Q0  33823403328671744     5  0.695  myRun   \n",
       "5   MB001     Q0  34703780100448257     6  0.688  myRun   \n",
       "6   MB001     Q0  29059262076420096     7  0.680  myRun   \n",
       "7   MB001     Q0  29486393336008704     8  0.668  myRun   \n",
       "8   MB001     Q0  30319208176820224     9  0.664  myRun   \n",
       "9   MB001     Q0  29564786882646016    10  0.661  myRun   \n",
       "\n",
       "                                            document  \n",
       "0  BBC News - BBC World Service cuts to be outlin...  \n",
       "1  BBC to cut 360 jobs as it cuts online budget: ...  \n",
       "2  [BBC News] Major cuts to BBC World Service: BB...  \n",
       "3  BBC World Service outlines cuts to staff http:...  \n",
       "4  World Service Cuts: Why We Need the BBC http:/...  \n",
       "5  Another great staff meeting at AHS. We have st...  \n",
       "6  Is your staff safe? Who is training your staff...  \n",
       "7  BBC to shed nearly a quarter of online staff -...  \n",
       "8  I think the BBC world service could be saved.....  \n",
       "9  BBC News - BBC to cut online budget by 25% htt...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge results_A1 and documents\n",
    "results_A1_doc = results_A1.merge(documents, left_on='docID', right_on='docID', how='left')\n",
    "\n",
    "# Show first 10 rows\n",
    "results_A1_doc.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queryID</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MB001</td>\n",
       "      <td>BBC World Service staff cuts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MB002</td>\n",
       "      <td>2022 FIFA soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MB003</td>\n",
       "      <td>Haiti Aristide return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MB004</td>\n",
       "      <td>Mexico drug war</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MB005</td>\n",
       "      <td>NIST computer security</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MB006</td>\n",
       "      <td>NSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MB007</td>\n",
       "      <td>Pakistan diplomat arrest murder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MB008</td>\n",
       "      <td>phone hacking British politicians</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MB009</td>\n",
       "      <td>Toyota Recall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MB010</td>\n",
       "      <td>Egyptian protesters attack museum</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  queryID                              query\n",
       "0   MB001       BBC World Service staff cuts\n",
       "1   MB002                   2022 FIFA soccer\n",
       "2   MB003              Haiti Aristide return\n",
       "3   MB004                    Mexico drug war\n",
       "4   MB005             NIST computer security\n",
       "5   MB006                                NSA\n",
       "6   MB007    Pakistan diplomat arrest murder\n",
       "7   MB008  phone hacking British politicians\n",
       "8   MB009                      Toyota Recall\n",
       "9   MB010  Egyptian protesters attack museum"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read query from file\n",
    "# Also, if you are using Google Colab, change the file path in line 4 to \"topics_MB1-49.txt\"\n",
    "queries_lst = []\n",
    "query_file = open('topics_MB1-49.txt', 'r')\n",
    "\n",
    "while True:\n",
    "    # Get next line from file\n",
    "    line = query_file.readline()\n",
    "\n",
    "    # if line is empty means end of file is reached\n",
    "    if not line:\n",
    "        break\n",
    "\n",
    "    tmp = []\n",
    "    if line.split(' ')[0] == '<num>':\n",
    "        # We first read query id\n",
    "        tmp.append(line.split(' ')[2])\n",
    "        line = query_file.readline()\n",
    "        # Then we read the query\n",
    "        tmp.append(' '.join(line.split(' ')[1:-1]).strip())\n",
    "        queries_lst.append(tmp)\n",
    "\n",
    "query_file.close()\n",
    "\n",
    "# We also save the queries into a Pandas dataframe with two columns - queryID and query\n",
    "queries = pd.DataFrame(queries_lst, columns = ['queryID', 'query'])\n",
    "queries.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Data Pre-processing***\n",
    "\n",
    "After we have imported all the data, we need to pre-process the data in order to get a better result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions we are going to use in the data preprocessing step\n",
    "\n",
    "# remove URLs\n",
    "def remove_URL(text):\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "\n",
    "# remove stopwords\n",
    "# We use stopwords provided by NLTK\n",
    "stopwords_lst = stopwords.words('english')\n",
    "def remove_stopwords(text):\n",
    "    lst = text.split(' ')\n",
    "    result = []\n",
    "    for i in range(0, len(lst)):\n",
    "        if not (lst[i] in stopwords_lst):\n",
    "            result.append(lst[i])\n",
    "    return ' '.join(result)\n",
    "\n",
    "# stemming words\n",
    "porter_stemmer = PorterStemmer()\n",
    "def stemming(text):\n",
    "    lst = text.split(' ')\n",
    "    result = []\n",
    "    for i in range(0, len(lst)):\n",
    "        result.append(porter_stemmer.stem(lst[i]))\n",
    "    return ' '.join(result)\n",
    "\n",
    "# remove punctuations\n",
    "def remove_punctuation(text):\n",
    "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "    return punctuationfree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the functions we defined in the previous cell to process both queries and documents\n",
    "# We will store processed data into a new column called cleaned_document or cleaned_query\n",
    "\n",
    "# remove URLs\n",
    "queries['cleaned_query'] = queries['query'].apply(lambda x:remove_URL(x))\n",
    "results_A1_doc['cleaned_document'] = results_A1_doc['document'].apply(lambda x: remove_URL(str(x)))\n",
    "\n",
    "# lowercasing the words\n",
    "queries['cleaned_query'] = queries['cleaned_query'].apply(lambda x: x.lower())\n",
    "results_A1_doc['cleaned_document'] = results_A1_doc['cleaned_document'].apply(lambda x: x.lower())\n",
    "\n",
    "# remove stopwords\n",
    "queries['cleaned_query'] = queries['cleaned_query'].apply(lambda x: remove_stopwords(x))\n",
    "results_A1_doc['cleaned_document'] = results_A1_doc['cleaned_document'].apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "# stemming words\n",
    "queries['cleaned_query'] = queries['cleaned_query'].apply(lambda x: stemming(x))\n",
    "results_A1_doc['cleaned_document'] = results_A1_doc['cleaned_document'].apply(lambda x: stemming(x))\n",
    "\n",
    "# remove punctuations\n",
    "queries['cleaned_query'] = queries['cleaned_query'].apply(lambda x:remove_punctuation(x))\n",
    "results_A1_doc['cleaned_document'] = results_A1_doc['cleaned_document'].apply(lambda x: remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queryID</th>\n",
       "      <th>query</th>\n",
       "      <th>cleaned_query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MB001</td>\n",
       "      <td>BBC World Service staff cuts</td>\n",
       "      <td>bbc world servic staff cut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MB002</td>\n",
       "      <td>2022 FIFA soccer</td>\n",
       "      <td>2022 fifa soccer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MB003</td>\n",
       "      <td>Haiti Aristide return</td>\n",
       "      <td>haiti aristid return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MB004</td>\n",
       "      <td>Mexico drug war</td>\n",
       "      <td>mexico drug war</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MB005</td>\n",
       "      <td>NIST computer security</td>\n",
       "      <td>nist comput secur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MB006</td>\n",
       "      <td>NSA</td>\n",
       "      <td>nsa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MB007</td>\n",
       "      <td>Pakistan diplomat arrest murder</td>\n",
       "      <td>pakistan diplomat arrest murder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MB008</td>\n",
       "      <td>phone hacking British politicians</td>\n",
       "      <td>phone hack british politician</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MB009</td>\n",
       "      <td>Toyota Recall</td>\n",
       "      <td>toyota recal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MB010</td>\n",
       "      <td>Egyptian protesters attack museum</td>\n",
       "      <td>egyptian protest attack museum</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  queryID                              query                    cleaned_query\n",
       "0   MB001       BBC World Service staff cuts       bbc world servic staff cut\n",
       "1   MB002                   2022 FIFA soccer                 2022 fifa soccer\n",
       "2   MB003              Haiti Aristide return             haiti aristid return\n",
       "3   MB004                    Mexico drug war                  mexico drug war\n",
       "4   MB005             NIST computer security                nist comput secur\n",
       "5   MB006                                NSA                              nsa\n",
       "6   MB007    Pakistan diplomat arrest murder  pakistan diplomat arrest murder\n",
       "7   MB008  phone hacking British politicians    phone hack british politician\n",
       "8   MB009                      Toyota Recall                     toyota recal\n",
       "9   MB010  Egyptian protesters attack museum   egyptian protest attack museum"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show top 10 queries\n",
    "queries.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queryID</th>\n",
       "      <th>unused</th>\n",
       "      <th>docID</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>tag</th>\n",
       "      <th>document</th>\n",
       "      <th>cleaned_document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MB001</td>\n",
       "      <td>Q0</td>\n",
       "      <td>30198105513140224</td>\n",
       "      <td>1</td>\n",
       "      <td>0.865</td>\n",
       "      <td>myRun</td>\n",
       "      <td>BBC News - BBC World Service cuts to be outlin...</td>\n",
       "      <td>bbc news  bbc world servic cut outlin staff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MB001</td>\n",
       "      <td>Q0</td>\n",
       "      <td>29552940691759104</td>\n",
       "      <td>2</td>\n",
       "      <td>0.786</td>\n",
       "      <td>myRun</td>\n",
       "      <td>BBC to cut 360 jobs as it cuts online budget: ...</td>\n",
       "      <td>bbc cut 360 job cut onlin budget bbc cut aroun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MB001</td>\n",
       "      <td>Q0</td>\n",
       "      <td>29983478363717633</td>\n",
       "      <td>3</td>\n",
       "      <td>0.758</td>\n",
       "      <td>myRun</td>\n",
       "      <td>[BBC News] Major cuts to BBC World Service: BB...</td>\n",
       "      <td>bbc news major cut bbc world service bbc world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MB001</td>\n",
       "      <td>Q0</td>\n",
       "      <td>30260724248870912</td>\n",
       "      <td>4</td>\n",
       "      <td>0.722</td>\n",
       "      <td>myRun</td>\n",
       "      <td>BBC World Service outlines cuts to staff http:...</td>\n",
       "      <td>bbc world servic outlin cut staff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MB001</td>\n",
       "      <td>Q0</td>\n",
       "      <td>33823403328671744</td>\n",
       "      <td>5</td>\n",
       "      <td>0.695</td>\n",
       "      <td>myRun</td>\n",
       "      <td>World Service Cuts: Why We Need the BBC http:/...</td>\n",
       "      <td>world servic cuts need bbc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MB001</td>\n",
       "      <td>Q0</td>\n",
       "      <td>34703780100448257</td>\n",
       "      <td>6</td>\n",
       "      <td>0.688</td>\n",
       "      <td>myRun</td>\n",
       "      <td>Another great staff meeting at AHS. We have st...</td>\n",
       "      <td>anoth great staff meet ahs staff meet everi we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MB001</td>\n",
       "      <td>Q0</td>\n",
       "      <td>29059262076420096</td>\n",
       "      <td>7</td>\n",
       "      <td>0.680</td>\n",
       "      <td>myRun</td>\n",
       "      <td>Is your staff safe? Who is training your staff...</td>\n",
       "      <td>staff safe train staff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MB001</td>\n",
       "      <td>Q0</td>\n",
       "      <td>29486393336008704</td>\n",
       "      <td>8</td>\n",
       "      <td>0.668</td>\n",
       "      <td>myRun</td>\n",
       "      <td>BBC to shed nearly a quarter of online staff -...</td>\n",
       "      <td>bbc shed nearli quarter onlin staff  bbc make ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MB001</td>\n",
       "      <td>Q0</td>\n",
       "      <td>30319208176820224</td>\n",
       "      <td>9</td>\n",
       "      <td>0.664</td>\n",
       "      <td>myRun</td>\n",
       "      <td>I think the BBC world service could be saved.....</td>\n",
       "      <td>think bbc world servic could saved cut bbc uk ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MB001</td>\n",
       "      <td>Q0</td>\n",
       "      <td>29564786882646016</td>\n",
       "      <td>10</td>\n",
       "      <td>0.661</td>\n",
       "      <td>myRun</td>\n",
       "      <td>BBC News - BBC to cut online budget by 25% htt...</td>\n",
       "      <td>bbc news  bbc cut onlin budget 25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  queryID unused              docID  rank  score    tag  \\\n",
       "0   MB001     Q0  30198105513140224     1  0.865  myRun   \n",
       "1   MB001     Q0  29552940691759104     2  0.786  myRun   \n",
       "2   MB001     Q0  29983478363717633     3  0.758  myRun   \n",
       "3   MB001     Q0  30260724248870912     4  0.722  myRun   \n",
       "4   MB001     Q0  33823403328671744     5  0.695  myRun   \n",
       "5   MB001     Q0  34703780100448257     6  0.688  myRun   \n",
       "6   MB001     Q0  29059262076420096     7  0.680  myRun   \n",
       "7   MB001     Q0  29486393336008704     8  0.668  myRun   \n",
       "8   MB001     Q0  30319208176820224     9  0.664  myRun   \n",
       "9   MB001     Q0  29564786882646016    10  0.661  myRun   \n",
       "\n",
       "                                            document  \\\n",
       "0  BBC News - BBC World Service cuts to be outlin...   \n",
       "1  BBC to cut 360 jobs as it cuts online budget: ...   \n",
       "2  [BBC News] Major cuts to BBC World Service: BB...   \n",
       "3  BBC World Service outlines cuts to staff http:...   \n",
       "4  World Service Cuts: Why We Need the BBC http:/...   \n",
       "5  Another great staff meeting at AHS. We have st...   \n",
       "6  Is your staff safe? Who is training your staff...   \n",
       "7  BBC to shed nearly a quarter of online staff -...   \n",
       "8  I think the BBC world service could be saved.....   \n",
       "9  BBC News - BBC to cut online budget by 25% htt...   \n",
       "\n",
       "                                    cleaned_document  \n",
       "0       bbc news  bbc world servic cut outlin staff   \n",
       "1  bbc cut 360 job cut onlin budget bbc cut aroun...  \n",
       "2  bbc news major cut bbc world service bbc world...  \n",
       "3                 bbc world servic outlin cut staff   \n",
       "4                        world servic cuts need bbc   \n",
       "5  anoth great staff meet ahs staff meet everi we...  \n",
       "6                            staff safe train staff   \n",
       "7  bbc shed nearli quarter onlin staff  bbc make ...  \n",
       "8  think bbc world servic could saved cut bbc uk ...  \n",
       "9                 bbc news  bbc cut onlin budget 25   "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show top 10 results from A1\n",
    "results_A1_doc.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***BERT word embadding***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the pre-trained model from HuggingFace\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use BERT fo the word embadding for all the documents from result of assignment 1\n",
    "document_embeddings = model.encode(results_A1_doc['cleaned_document'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bl/5cdhhphs6bxf8j7ylf60kpzh0000gn/T/ipykernel_8549/1895283887.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tmp_df['cos_sim'] = cos_sim[0]\n",
      "/usr/local/lib/python3.9/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "start = 0\n",
    "end = 1000\n",
    "\n",
    "for index_query, row_query in queries.iterrows():\n",
    "    # get the query we are going to use for current loop\n",
    "    selected_query_id = row_query['queryID']\n",
    "    selected_query = row_query['cleaned_query']\n",
    "\n",
    "    # use BERT do the word embedding for the selected query and select word embadding results for documents\n",
    "    tmp_doc_embeddings = document_embeddings[start:end]\n",
    "    query_embedding = model.encode(selected_query)\n",
    "\n",
    "    # compute the cosine similarity\n",
    "    cos_sim = util.cos_sim(query_embedding, tmp_doc_embeddings).tolist()\n",
    "\n",
    "    # save query id and cosine similarity into a temperary dataframe\n",
    "    tmp_df = results_A1_doc[results_A1_doc['queryID'] == selected_query_id]\n",
    "    tmp_df['cos_sim'] = cos_sim[0]\n",
    "\n",
    "    # sort dataframe according to the cosine similarity score\n",
    "    tmp_df.sort_values(by='cos_sim', ascending=False, inplace=True)\n",
    "\n",
    "    # save results to file Result_method1.txt\n",
    "    result_file = open('Result_method1.txt', 'a')\n",
    "\n",
    "    counter = 0\n",
    "    for index, row in tmp_df.iterrows():\n",
    "        counter += 1\n",
    "        id = str(row[\"docID\"])\n",
    "        score = str(round(row['cos_sim'], 3))\n",
    "        result_file.writelines(selected_query_id + ' Q0 ' + id + ' ' + str(counter) + ' ' + score + ' myRun\\n')\n",
    "    result_file.close()\n",
    "    \n",
    "    start = end\n",
    "    end += 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Result***\n",
    "\n",
    "After previous step, the results will be save into *Result_method3.txt*. In order to view this file, you can either open it in Colab, or download it to your own computer (Find *Result_method3.txt* at left -> Right click it -> Click download)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Reference:***  \\\n",
    "[Calculating Document Similarities using BERT, word2vec, and other models](https://medium.com/p/b2c1a29c9630)  \\\n",
    "[BERT For Measuring Text Similarity](https://towardsdatascience.com/bert-for-measuring-text-similarity-eec91c6bf9e1)  \\\n",
    "[List of pre-trained models from HuggingFace](https://www.sbert.net/docs/pretrained_models.html)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
